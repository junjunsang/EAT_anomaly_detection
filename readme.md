#  EAT-LoRA Anomaly Detection (DCASE Task 2)

ì´ í”„ë¡œì íŠ¸ëŠ” **DCASE Task 2 (Unsupervised Anomalous Sound Detection)** ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

**Efficient Audio Transformer (EAT)** ë¥¼ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, **LoRA (Low-Rank Adaptation)** ë¥¼ ì ìš©í•˜ì—¬ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì ì¸ íŠœë‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ìƒ íƒì§€ ë‹¨ê³„ì—ì„œëŠ” **Deep SVDD** ë°©ì‹ê³¼ **Ensemble (KNN + Statistics)** ë°©ì‹ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ“‚ Project Structure

```bash
EAT-Anomaly-Detection/
â”œâ”€â”€ dev_data/                   # (Not included in repo) Raw Dataset
â”‚   â”œâ”€â”€ train/                  # Normal data for training
â”‚   â””â”€â”€ test/                   # Test data (Normal + Anomaly)
â”œâ”€â”€ svdd_models_per_type/       # Saved SVDD models (Auto-generated)
â”œâ”€â”€ model.py                    # EAT Classifier with LoRA
â”œâ”€â”€ dataset.py                  # DCASE Dataset Loader
â”œâ”€â”€ preprocessing.py            # Mel-Spectrogram transformation
â”œâ”€â”€ train.py                    # Step 1: Encoder Representation Learning
â”œâ”€â”€ extract_embeddings.py       # Step 2: Extract embeddings from normal data
â”œâ”€â”€ train_deepSVDD.py           # Step 3-A: Train Deep SVDD models
â”œâ”€â”€ evaluate_deepSVDD.py        # Step 3-A: Evaluate with Deep SVDD
â”œâ”€â”€ evaluate.py                 # Step 3-B: Evaluate with Ensemble (KNN+Stats)
â””â”€â”€ datashape.py                # Data integrity check
````

##  Prerequisites

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜

```bash
pip install torch torchaudio transformers peft pyod scikit-learn tqdm numpy scipy joblib
```

##  Usage Pipeline

ì „ì²´ íŒŒì´í”„ë¼ì¸ì€ **[í•™ìŠµ] -\> [íŠ¹ì§• ì¶”ì¶œ] -\> [ì´ìƒ íƒì§€ í‰ê°€]** ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

### 0\. Data Preparation

DCASE ë°ì´í„°ì…‹ì„ `dev_data` í´ë”ì— ìœ„ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

  - `dev_data/train/`: ì •ìƒ ë°ì´í„° (í•™ìŠµìš©)
  - `dev_data/test/`: ì •ìƒ ë° ì´ìƒ ë°ì´í„° (í…ŒìŠ¤íŠ¸ìš©)

ë°ì´í„°ê°€ ì˜ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´:

```bash
python datashape.py
```

### 1\. Encoder Training (Representation Learning)

ê¸°ê³„ì˜ ì†ì„±(Attribute)ì„ ë¶„ë¥˜í•˜ëŠ” ë³´ì¡° ê³¼ì œ(Auxiliary Task)ë¥¼ í†µí•´ ì¸ì½”ë”ë¥¼ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

  - **Output:** `best_encoder_model.pth` (ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°€ì¤‘ì¹˜)

<!-- end list -->

```bash
python train.py
```

### 2\. Feature Extraction

í•™ìŠµëœ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ `train` í´ë”(ì •ìƒ ë°ì´í„°)ì˜ ì„ë² ë”©ê³¼ í†µê³„ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

  - **Output:** `normal_embeddings.pt`, `normal_stats.pt`

<!-- end list -->

```bash
python extract_embeddings.py
```

### 3\. Anomaly Detection & Evaluation

ë‘ ê°€ì§€ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Option A: Deep SVDD (Recommended)

ê¸°ê³„ íƒ€ì…(Machine Type)ë³„ë¡œ ë…ë¦½ëœ SVDD ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.

```bash
# SVDD ëª¨ë¸ í•™ìŠµ (svdd_models_per_type í´ë”ì— ì €ì¥ë¨)
python train_deepSVDD.py

# í‰ê°€ ìˆ˜í–‰ (AUROC ì ìˆ˜ ì¶œë ¥)
python evaluate_deepSVDD.py
```

#### Option B: Ensemble (KNN + Statistics)

ë³„ë„ì˜ ì¶”ê°€ í•™ìŠµ ì—†ì´, ì„ë² ë”© ê±°ë¦¬(Cosine)ì™€ í†µê³„ì  ê±°ë¦¬(Mahalanobis)ë¥¼ ê²°í•©í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.

  - `-k`: KNN íƒìƒ‰ ì‹œ ê³ ë ¤í•  ì´ì›ƒ ìˆ˜ (ê¸°ë³¸ê°’: 1)
  - `--w`: ì„ë² ë”© ì ìˆ˜ ê°€ì¤‘ì¹˜ (0.0 \~ 1.0, ê¸°ë³¸ê°’: 1.0)

<!-- end list -->

```bash
python evaluate.py -k 1 --w 0.5
```


```

```

